{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Josephrp/Auto-GPT-Forge/blob/master/Open_Interpreter%5BJARVIS%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to JARVIS.\n",
        "\n",
        "## The core of JARVIS is powered by [Open Interpreter](https://openinterpreter.com/):\n",
        "\n",
        "Please set your API keys to begin."
      ],
      "metadata": {
        "id": "WGodUl4zncbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "eleven_labs_api_key = getpass.getpass(\"Eleven Labs API Key: \") # https://elevenlabs.io/speech-synthesis\n",
        "openai_api_key = getpass(\"OpenAI API Key: \") # https://platform.openai.com/account/api-keys"
      ],
      "metadata": {
        "id": "LI_6uNbs_K9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install (`Restart Runtime` after this)"
      ],
      "metadata": {
        "id": "lE2GSFLJoOtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open-interpreter\n",
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!pip install gradio -q\n",
        "!pip install elevenlabs\n",
        "!pip install tiktoken==0.5.0 --force -q"
      ],
      "metadata": {
        "id": "iwI1Dhv7uzD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "Import dependencies, download and install [Whisper](https://github.com/openai/whisper), set [OpenAI API key](https://platform.openai.com/account/api-keys), and [Eleven Labs API key](https://elevenlabs.io/speech-synthesis)\n"
      ],
      "metadata": {
        "id": "aeic06e-o5Wh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Misc Imports"
      ],
      "metadata": {
        "id": "CjrhRX6fWkXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import time"
      ],
      "metadata": {
        "id": "XbzTmzACWlyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Download and load [Whisper](https://github.com/openai/whisper)"
      ],
      "metadata": {
        "id": "TQ9iTzMQYs9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"base\")"
      ],
      "metadata": {
        "id": "YstqtPbGoWXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define transcription function\n"
      ],
      "metadata": {
        "id": "Pu6EP1W3o_cU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(audio):\n",
        "\n",
        "    # load audio and pad/trim it to fit 30 seconds\n",
        "    audio = whisper.load_audio(audio)\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "\n",
        "    # make log-Mel spectrogram and move to the same device as the model\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "    # detect the spoken language\n",
        "    _, probs = model.detect_language(mel)\n",
        "\n",
        "    # decode the audio\n",
        "    options = whisper.DecodingOptions()\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    return result.text"
      ],
      "metadata": {
        "id": "JtTvvQQPcOZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set [OpenAI](https://openai.com) API Key"
      ],
      "metadata": {
        "id": "T9KaJXLXQtYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import interpreter\n",
        "\n",
        "interpreter.api_key = openai_api_key\n",
        "interpreter.auto_run = True"
      ],
      "metadata": {
        "id": "gpNOy1sLQs0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set [ElevenLabs](https://elevenlabs.io/) API Key"
      ],
      "metadata": {
        "id": "kf751XxlyOd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from elevenlabs import generate, play, set_api_key\n",
        "\n",
        "set_api_key(eleven_labs_api_key)"
      ],
      "metadata": {
        "id": "qRcI6nlx8Cun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define audio length"
      ],
      "metadata": {
        "id": "Wlawp3p5pzSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "from pydub import AudioSegment\n",
        "\n",
        "def get_audio_length(audio_bytes):\n",
        "  # Create a BytesIO object from the byte array\n",
        "  byte_io = io.BytesIO(audio_bytes)\n",
        "\n",
        "  # Load the audio data with PyDub\n",
        "  audio = AudioSegment.from_mp3(byte_io)\n",
        "\n",
        "  # Get the length of the audio in milliseconds\n",
        "  length_ms = len(audio)\n",
        "\n",
        "  # Optionally convert to seconds\n",
        "  length_s = length_ms / 1000.0\n",
        "\n",
        "  return length_s"
      ],
      "metadata": {
        "id": "o78_YmQwEBvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define the speak function which handles audio generation\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "sIk0PAavp7XB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def speak(text):\n",
        "  speaking = True\n",
        "  audio = generate(\n",
        "      text=text,\n",
        "      voice=\"Daniel\"\n",
        "  )\n",
        "  play(audio, notebook=True)\n",
        "\n",
        "  audio_length = get_audio_length(audio)\n",
        "  time.sleep(audio_length)"
      ],
      "metadata": {
        "id": "Ru3Z4M_L_FCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "X93f9Q5E_Gd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title JARVIS\n",
        "# @markdown ### **Setup Instructions**\n",
        "# @markdown 1. Run this cell, then scroll down to use the interface (don't click the link, and give the interface a minute to load).\n",
        "# @markdown 2. Press the `Record from Microphone` button.\n",
        "# @markdown 3. Allow access to your microphone, then speak your command.\n",
        "# @markdown 4. Stop the recording, then press `Submit`.\n",
        "# @markdown\n",
        "# @markdown\n",
        "# @markdown JARVIS will respond verbally + carry out your command.\n",
        "\n",
        "last_sentence = \"\"\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    chatbot = gr.Chatbot()\n",
        "    audio_input = gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
        "    btn = gr.Button(\"Submit\")\n",
        "\n",
        "    def transcribe(audio):\n",
        "      audio = whisper.load_audio(audio)\n",
        "      audio = whisper.pad_or_trim(audio)\n",
        "      mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "      _, probs = model.detect_language(mel)\n",
        "      options = whisper.DecodingOptions()\n",
        "      result = whisper.decode(model, mel, options)\n",
        "      return result.text\n",
        "\n",
        "    def add_user_message(audio, history):\n",
        "        user_message = transcribe(audio)\n",
        "        return history + [[user_message, None]]\n",
        "\n",
        "    def bot(history):\n",
        "        global last_sentence\n",
        "\n",
        "        user_message = history[-1][0]\n",
        "        history[-1][1] = \"\"\n",
        "        active_block_type = \"\"\n",
        "        language = \"\"\n",
        "        for chunk in interpreter.chat(user_message, stream=True, display=False):\n",
        "\n",
        "            # Message\n",
        "            if \"message\" in chunk:\n",
        "              if active_block_type != \"message\":\n",
        "                active_block_type = \"message\"\n",
        "              history[-1][1] += chunk[\"message\"]\n",
        "\n",
        "              last_sentence += chunk[\"message\"]\n",
        "              if any([punct in last_sentence for punct in \".?!\\n\"]):\n",
        "                yield history\n",
        "                speak(last_sentence)\n",
        "                last_sentence = \"\"\n",
        "              else:\n",
        "                yield history\n",
        "\n",
        "            # Code\n",
        "            if \"language\" in chunk:\n",
        "              language = chunk[\"language\"]\n",
        "            if \"code\" in chunk:\n",
        "              if active_block_type != \"code\":\n",
        "                active_block_type = \"code\"\n",
        "                history[-1][1] += f\"\\n```{language}\"\n",
        "              history[-1][1] += chunk[\"code\"]\n",
        "              yield history\n",
        "\n",
        "            # Output\n",
        "            if \"executing\" in chunk:\n",
        "              history[-1][1] += \"\\n```\\n\\n```text\\n\"\n",
        "              yield history\n",
        "            if \"output\" in chunk:\n",
        "              if chunk[\"output\"] != \"KeyboardInterrupt\":\n",
        "                history[-1][1] += chunk[\"output\"] + \"\\n\"\n",
        "                yield history\n",
        "            if \"active_line\" in chunk and chunk[\"active_line\"] == None:\n",
        "              history[-1][1] = history[-1][1].strip()\n",
        "              history[-1][1] += \"\\n```\\n\"\n",
        "              yield history\n",
        "\n",
        "        if last_sentence:\n",
        "          speak(last_sentence)\n",
        "\n",
        "    btn.click(add_user_message, [audio_input, chatbot], [chatbot]).then(\n",
        "        bot, chatbot, chatbot\n",
        "    )\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "O-xIJaH949uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Text-only JARVIS\n",
        "# @markdown Run this cell for a ChatGPT-like interface.\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "\n",
        "    def user(user_message, history):\n",
        "        return \"\", history + [[user_message, None]]\n",
        "\n",
        "    def bot(history):\n",
        "\n",
        "        user_message = history[-1][0]\n",
        "        history[-1][1] = \"\"\n",
        "        active_block_type = \"\"\n",
        "\n",
        "        for chunk in interpreter.chat(user_message, stream=True, display=False):\n",
        "\n",
        "            # Message\n",
        "            if \"message\" in chunk:\n",
        "              if active_block_type != \"message\":\n",
        "                active_block_type = \"message\"\n",
        "              history[-1][1] += chunk[\"message\"]\n",
        "              yield history\n",
        "\n",
        "            # Code\n",
        "            if \"language\" in chunk:\n",
        "              language = chunk[\"language\"]\n",
        "            if \"code\" in chunk:\n",
        "              if active_block_type != \"code\":\n",
        "                active_block_type = \"code\"\n",
        "                history[-1][1] += f\"\\n```{language}\\n\"\n",
        "              history[-1][1] += chunk[\"code\"]\n",
        "              yield history\n",
        "\n",
        "            # Output\n",
        "            if \"executing\" in chunk:\n",
        "              history[-1][1] += \"\\n```\\n\\n```text\\n\"\n",
        "              yield history\n",
        "            if \"output\" in chunk:\n",
        "              if chunk[\"output\"] != \"KeyboardInterrupt\":\n",
        "                history[-1][1] += chunk[\"output\"] + \"\\n\"\n",
        "                yield history\n",
        "            if \"end_of_execution\" in chunk:\n",
        "              history[-1][1] = history[-1][1].strip()\n",
        "              history[-1][1] += \"\\n```\\n\"\n",
        "              yield history\n",
        "\n",
        "    msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
        "        bot, chatbot, chatbot\n",
        "    )\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "mL1LS3NTlTtv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lE2GSFLJoOtI",
        "T9KaJXLXQtYJ",
        "TQ9iTzMQYs9u",
        "udVxiw4oyMh-"
      ],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}